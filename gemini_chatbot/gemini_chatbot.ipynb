{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# See what models you have\n",
        "for m in genai.list_models():\n",
        "    print(m.name, \"->\", m.supported_generation_methods)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "utXt9wyJ04hz",
        "outputId": "8a217b6f-99b3-4f65-baaf-66eb171409c1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/embedding-gecko-001 -> ['embedText', 'countTextTokens']\n",
            "models/gemini-2.5-pro-preview-03-25 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro-preview-05-06 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro-preview-06-05 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-pro -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-exp -> ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-001 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-exp-image-generation -> ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.0-flash-lite-001 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite-preview-02-05 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-lite-preview -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-pro-exp -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-pro-exp-02-05 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-exp-1206 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp-01-21 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.0-flash-thinking-exp-1219 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-preview-tts -> ['countTokens', 'generateContent']\n",
            "models/gemini-2.5-pro-preview-tts -> ['countTokens', 'generateContent']\n",
            "models/learnlm-2.0-flash-experimental -> ['generateContent', 'countTokens']\n",
            "models/gemma-3-1b-it -> ['generateContent', 'countTokens']\n",
            "models/gemma-3-4b-it -> ['generateContent', 'countTokens']\n",
            "models/gemma-3-12b-it -> ['generateContent', 'countTokens']\n",
            "models/gemma-3-27b-it -> ['generateContent', 'countTokens']\n",
            "models/gemma-3n-e4b-it -> ['generateContent', 'countTokens']\n",
            "models/gemma-3n-e2b-it -> ['generateContent', 'countTokens']\n",
            "models/gemini-flash-latest -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-flash-lite-latest -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-pro-latest -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-lite -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-image-preview -> ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-image -> ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-preview-09-2025 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-2.5-flash-lite-preview-09-2025 -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-3-pro-preview -> ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
            "models/gemini-3-pro-image-preview -> ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "models/nano-banana-pro-preview -> ['generateContent', 'countTokens', 'batchGenerateContent']\n",
            "models/gemini-robotics-er-1.5-preview -> ['generateContent', 'countTokens']\n",
            "models/gemini-2.5-computer-use-preview-10-2025 -> ['generateContent', 'countTokens']\n",
            "models/embedding-001 -> ['embedContent']\n",
            "models/text-embedding-004 -> ['embedContent']\n",
            "models/gemini-embedding-exp-03-07 -> ['embedContent', 'countTextTokens', 'countTokens']\n",
            "models/gemini-embedding-exp -> ['embedContent', 'countTextTokens', 'countTokens']\n",
            "models/gemini-embedding-001 -> ['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent']\n",
            "models/aqa -> ['generateAnswer']\n",
            "models/imagen-4.0-generate-preview-06-06 -> ['predict']\n",
            "models/imagen-4.0-ultra-generate-preview-06-06 -> ['predict']\n",
            "models/imagen-4.0-generate-001 -> ['predict']\n",
            "models/imagen-4.0-ultra-generate-001 -> ['predict']\n",
            "models/imagen-4.0-fast-generate-001 -> ['predict']\n",
            "models/veo-2.0-generate-001 -> ['predictLongRunning']\n",
            "models/veo-3.0-generate-001 -> ['predictLongRunning']\n",
            "models/veo-3.0-fast-generate-001 -> ['predictLongRunning']\n",
            "models/veo-3.1-generate-preview -> ['predictLongRunning']\n",
            "models/veo-3.1-fast-generate-preview -> ['predictLongRunning']\n",
            "models/gemini-2.0-flash-live-001 -> ['bidiGenerateContent', 'countTokens']\n",
            "models/gemini-live-2.5-flash-preview -> ['bidiGenerateContent', 'countTokens']\n",
            "models/gemini-2.5-flash-live-preview -> ['bidiGenerateContent', 'countTokens']\n",
            "models/gemini-2.5-flash-native-audio-latest -> ['countTokens', 'bidiGenerateContent']\n",
            "models/gemini-2.5-flash-native-audio-preview-09-2025 -> ['countTokens', 'bidiGenerateContent']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit google-genai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG8Q6TbS4bY9",
        "outputId": "532f4b61-ec25-43f2-dd92-700cc5f1ee7a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.51.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.52.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.11.10)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.51.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m120.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.51.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# üöÄ STEP 1: INSTALL NEW GEMINI SDK\n",
        "# ============================================\n",
        "!pip uninstall -y google-generativeai\n",
        "!pip install -U google-genai\n",
        "\n",
        "# ============================================\n",
        "# üö® IMPORTANT: RESTART RUNTIME AFTER THIS CELL\n",
        "# ============================================\n",
        "# Runtime > Restart runtime > Yes\n",
        "\n",
        "# ============================================\n",
        "# üß† STEP 2: IMPORTS & API KEY CONFIGURATION\n",
        "# ============================================\n",
        "from google import genai  # NEW SDK\n",
        "from google.genai import types  # for chat history\n",
        "\n",
        "# üîë ENTER YOUR *NEW* API KEY (IN QUOTES!!!)\n",
        "client = genai.Client(api_key=\"AIzaSyCZwFnIeaty4IX5vzMnp54rpaz3lJDSBV8\")\n",
        "\n",
        "# ============================================\n",
        "# üß™ STEP 3: TEST GEMINI CONNECTION\n",
        "# ============================================\n",
        "try:\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",  # or \"gemini-2.0-flash-001\"\n",
        "        contents=\"Say hello to Kelvin in 2 lines.\"\n",
        "    )\n",
        "    print(\"Gemini is working! üôå\\n\")\n",
        "    print(\"Test response:\", response.text)\n",
        "except Exception as e:\n",
        "    print(\"‚ùå ERROR! Gemini did not respond:\")\n",
        "    print(e)\n",
        "\n",
        "# ============================================\n",
        "# üí¨ STEP 4: CREATE CHATBOT WITH MEMORY\n",
        "# ============================================\n",
        "chat_history = []\n",
        "\n",
        "def personal_chatbot():\n",
        "    global chat_history\n",
        "    print(\"\\nü§ñ Kelvin's Gemini Chatbot (type 'quit' to stop)\")\n",
        "    print(\"--------------------------------------------------\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_msg = input(\"Kelvin: \")\n",
        "\n",
        "        if user_msg.lower().strip() in (\"quit\", \"bye\", \"exit\"):\n",
        "            print(\"Bot: It was great chatting with you. Bye! üëã\")\n",
        "            break\n",
        "\n",
        "        # Add user message to history\n",
        "        chat_history.append(\n",
        "            types.Content(role=\"user\", parts=[types.Part.from_text(text=user_msg)])\n",
        "        )\n",
        "\n",
        "        # Send full history to Gemini\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\",  # or \"gemini-2.0-flash-001\"\n",
        "            contents=chat_history,\n",
        "        )\n",
        "\n",
        "        bot_reply = response.text\n",
        "        print(\"\\nBot:\", bot_reply, \"\\n\")\n",
        "\n",
        "        # Add bot reply to history\n",
        "        chat_history.append(\n",
        "            types.Content(role=\"model\", parts=[types.Part.from_text(text=bot_reply)])\n",
        "        )\n",
        "\n",
        "# ============================================\n",
        "# ‚ñ∂Ô∏è STEP 5: START CHATBOT\n",
        "# ============================================\n",
        "# Run this function to start chatting:\n",
        "# personal_chatbot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elnVW35A2Ww4",
        "outputId": "5ba351d6-f244-4977-d6df-d6c4167c48e0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping google-generativeai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.52.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.11.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
            "Gemini is working! üôå\n",
            "\n",
            "Test response: Hello there, Kelvin!\n",
            "Wishing you a fantastic day.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "\n",
        "# Create a chat session with an empty history\n",
        "chat = model.start_chat(history=[])\n",
        "\n",
        "def chat_with_gemini():\n",
        "    print(\"ü§ñ Gemini Chatbot (type 'quit' to stop)\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower().strip() in [\"quit\", \"exit\", \"bye\"]:\n",
        "            print(\"Bot: Bye! üëã\")\n",
        "            break\n",
        "\n",
        "        reply = chat.send_message(user_input)\n",
        "        # Wrap text nicely for console display\n",
        "        print(\"Bot:\", textwrap.fill(reply.text, width=80))\n",
        "        print()\n",
        "\n",
        "chat_with_gemini()\n"
      ],
      "metadata": {
        "id": "VOGuzFgb07yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Redefine the model with an initial \"persona\" using the system instruction\n",
        "personal_model = genai.GenerativeModel(\n",
        "    \"gemini-1.5-flash\",\n",
        "    system_instruction=(\n",
        "        \"You are a personal AI assistant for Kelvin. \"\n",
        "        \"Speak in simple, clear language. \"\n",
        "        \"Explain technical things step by step. \"\n",
        "        \"Be friendly and encouraging.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "personal_chat = personal_model.start_chat(history=[])\n",
        "\n",
        "import textwrap\n",
        "\n",
        "def personal_chatbot():\n",
        "    print(\"üí¨ Kelvin's Personal Gemini Chatbot (type 'quit' to stop)\\n\")\n",
        "    while True:\n",
        "        user_input = input(\"Kelvin: \")\n",
        "        if user_input.lower().strip() in [\"quit\", \"exit\", \"bye\"]:\n",
        "            print(\"Bot: It was nice chatting with you. Bye! üëã\")\n",
        "            break\n",
        "\n",
        "        reply = personal_chat.send_message(user_input)\n",
        "        print(\"Bot:\", textwrap.fill(reply.text, width=80))\n",
        "        print()\n",
        "\n",
        "personal_chatbot()\n"
      ],
      "metadata": {
        "id": "9kLhC4DJ0_NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n"
      ],
      "metadata": {
        "id": "5hJBsYYb1C5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Use the same API key & model\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "web_model = genai.GenerativeModel(\n",
        "    \"gemini-1.5-flash\",\n",
        "    system_instruction=(\n",
        "        \"You are Kelvin's personal chatbot. \"\n",
        "        \"Answer clearly, step by step, and be supportive.\"\n",
        "    ),\n",
        ")\n",
        "\n",
        "def respond(message, history):\n",
        "    # Convert Gradio chat history into Gemini format if needed\n",
        "    if history is None:\n",
        "        history = []\n",
        "\n",
        "    # Build a chat session for each interaction\n",
        "    chat = web_model.start_chat(\n",
        "        history=[\n",
        "            {\"role\": \"user\", \"parts\": [m[0]]}\n",
        "            if i == 0 else\n",
        "            {\"role\": \"model\", \"parts\": [m[1]]}\n",
        "            for i, m in enumerate(history)\n",
        "            if m[0] is not None and m[1] is not None\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    response = chat.send_message(message)\n",
        "    bot_reply = response.text\n",
        "    history.append((message, bot_reply))\n",
        "    return bot_reply, history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## ü§ñ Kelvin's Personal Gemini Chatbot\")\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox(placeholder=\"Ask me anything...\")\n",
        "    clear = gr.Button(\"Clear\")\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [chatbot, chatbot])\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "0cEISpUp1GlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "def save_history(history, filename=None):\n",
        "    if filename is None:\n",
        "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"chat_history_{timestamp}.txt\"\n",
        "\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        for user_msg, bot_msg in history:\n",
        "            f.write(f\"You: {user_msg}\\n\")\n",
        "            f.write(f\"Bot: {bot_msg}\\n\")\n",
        "            f.write(\"-\" * 40 + \"\\n\")\n",
        "\n",
        "    print(f\"History saved to {filename}\")\n",
        "\n",
        "# Example (after using Gradio or your own history list):\n",
        "# save_history(history)\n"
      ],
      "metadata": {
        "id": "3MUobU4d1LkT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}